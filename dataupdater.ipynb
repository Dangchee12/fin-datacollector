{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfcbwD_UCiUz",
        "outputId": "5fa30198-d48d-480c-9f26-b1ff3e2c366e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import os\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load existing tickers from log.csv\n",
        "def load_existing_tickers(log_file):\n",
        "    if not os.path.exists(log_file):\n",
        "        return dict()\n",
        "    existing_tickers = dict()\n",
        "    with open(log_file, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "        for line in lines[1:]:  # Skip the header line\n",
        "            ticker, last_updated = line.strip().split(',')\n",
        "            existing_tickers[ticker] = datetime.strptime(last_updated, '%Y-%m-%d')\n",
        "    return existing_tickers\n",
        "\n",
        "# Function to update log.csv with new tickers\n",
        "def update_log(log_file, new_ticker, last_updated):\n",
        "    with open(log_file, 'a') as file:\n",
        "        file.write(f\"{new_ticker},{last_updated}\\n\")\n",
        "\n",
        "def remove_duplicates_from_log(log_file):\n",
        "    if not os.path.exists(log_file):\n",
        "        return\n",
        "\n",
        "    log_data = {}\n",
        "    with open(log_file, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "        for line in lines[1:]:\n",
        "            ticker, last_updated = line.strip().split(',')\n",
        "            log_data.setdefault(ticker, []).append(last_updated)\n",
        "\n",
        "    with open(log_file, 'w') as file:\n",
        "        file.write(\"Ticker,LastUpdated\\n\")\n",
        "        for ticker, dates in log_data.items():\n",
        "            latest_date = max(dates)\n",
        "            file.write(f\"{ticker},{latest_date}\\n\")\n",
        "\n",
        "# Function to fetch and store stock price data\n",
        "def fetch_stock_data(ticker_list, storage_folder, tracking_directory):\n",
        "    log_file = os.path.join(tracking_directory, 'log.csv')\n",
        "    existing_tickers = load_existing_tickers(log_file)\n",
        "\n",
        "    for ticker in ticker_list:\n",
        "        if ticker not in existing_tickers:\n",
        "            # Fetch data from Yahoo Finance\n",
        "            df = yf.download(ticker, end=datetime.today().strftime('%Y-%m-%d'))\n",
        "\n",
        "            # Group data by year\n",
        "            data_by_year = df.groupby(df.index.year)\n",
        "\n",
        "            # Create a folder for each ticker\n",
        "            ticker_directory = os.path.join(storage_folder, ticker[0], ticker)\n",
        "            os.makedirs(ticker_directory, exist_ok=True)\n",
        "\n",
        "            # Save data into separate CSV files for each year in the ticker folder\n",
        "            for year, year_data in data_by_year:\n",
        "                year_file_name = os.path.join(ticker_directory, f\"{year}.csv\")\n",
        "                year_data.to_csv(year_file_name)\n",
        "\n",
        "            # Update the log file\n",
        "            update_log(log_file, ticker, datetime.today().strftime('%Y-%m-%d'))\n",
        "            print(f\"Data for {ticker} saved to findata folder\")\n",
        "        else:\n",
        "            print(f\"Data for {ticker} already exists. Updating...\")\n",
        "            # Fetch data for the existing ticker from the last updated date onwards\n",
        "            last_updated = existing_tickers[ticker]\n",
        "            start_date = f\"{last_updated.year}-01-01\"\n",
        "            df = yf.download(ticker, start=start_date)\n",
        "\n",
        "            # Group data by year\n",
        "            data_by_year = df.groupby(df.index.year)\n",
        "\n",
        "            # Create a folder for each ticker\n",
        "            ticker_directory = os.path.join(storage_folder, ticker[0], ticker)\n",
        "            os.makedirs(ticker_directory, exist_ok=True)\n",
        "\n",
        "            # Save data into separate CSV files for each year in the ticker folder\n",
        "            for year, year_data in data_by_year:\n",
        "                year_file_name = os.path.join(ticker_directory, f\"{year}.csv\")\n",
        "                year_data.to_csv(year_file_name)\n",
        "\n",
        "            # Update the log file\n",
        "            update_log(log_file, ticker, datetime.today().strftime('%Y-%m-%d'))\n",
        "            print(f\"Data for {ticker} updated from {last_updated.strftime('%Y-%m-%d')} to today.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    storage_folder = \"/content/drive/MyDrive/findata/eoddata\"  # Change this to your desired storage folder\n",
        "    os.makedirs(storage_folder, exist_ok=True)\n",
        "\n",
        "    # Create a directory to store the tracking file\n",
        "    tracking_directory = \"/content/drive/MyDrive/findata/log\"\n",
        "    os.makedirs(tracking_directory, exist_ok=True)\n",
        "\n",
        "    # Prompt the user to upload a CSV file with a list of tickers\n",
        "    #csv_file_path = input(\"Please enter the path to the CSV file containing tickers: \")\n",
        "\n",
        "    # if not os.path.exists(csv_file_path):\n",
        "    #     print(\"CSV file not found.\")\n",
        "    # else:\n",
        "        # Read tickers from the CSV file\n",
        "    ticker_list = [\"AAPL\", \"MSFT\", \"GOOGL\"]#pd.read_csv(csv_file_path)['Ticker'].tolist()\n",
        "    fetch_stock_data(ticker_list, storage_folder, tracking_directory)\n",
        "\n",
        "    # Run the function to remove duplicates from the log file\n",
        "    log_file = os.path.join(tracking_directory, 'log.csv')\n",
        "    remove_duplicates_from_log(log_file)\n"
      ],
      "metadata": {
        "id": "evUBt7jpdANa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69eef303-b111-49f8-ffb5-ecba14bf489a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data for AAPL already exists. Updating...\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "Data for AAPL updated from 2023-09-28 to today.\n",
            "Data for MSFT already exists. Updating...\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "Data for MSFT updated from 2023-09-28 to today.\n",
            "Data for GOOGL already exists. Updating...\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "Data for GOOGL updated from 2023-09-28 to today.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}